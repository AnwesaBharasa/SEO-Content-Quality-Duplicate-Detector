SEO Content Quality & Duplicate Detector

This project analyzes webpage content to detect duplicate pages, flag thin content, and assess SEO content quality using NLP and machine learning.
Developed as part of an AI/ML role assignment, it combines text extraction, embedding similarity, and rule-based + ML classification for automated content evaluation.

ðŸš€ Overview

The system takes web page HTML or URLs as input and performs:

HTML Parsing â€“ Extracts title, main body text, and word count.

Feature Engineering â€“ Calculates readability (Flesch), sentence count, and top TF-IDF keywords.

Embedding Generation â€“ Uses SentenceTransformer (all-MiniLM-L6-v2) for semantic vectorization.

Duplicate Detection â€“ Computes cosine similarity between embeddings to flag near-duplicates.

Quality Labeling â€“ Categorizes each page as High, Medium, or Low quality based on rules and an ML classifier.

Real-Time Analysis â€“ analyze_url() function allows instant evaluation of any new URL.

ðŸ§° Tech Stack

Language: Python 3.9+

Core Environment: Jupyter / Kaggle Notebook

Libraries:
pandas, numpy, beautifulsoup4, lxml, scikit-learn,
sentence-transformers, textstat, nltk, tqdm, joblib, matplotlib

Optional: streamlit for interactive demo

ðŸ“‚ Project Structure
seo-content-quality-duplicate-detector/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ data.csv                      # Input dataset (URL or HTML)
â”‚   â”œâ”€â”€ extracted_content.csv         # Parsed text data
â”‚   â”œâ”€â”€ features_with_embeddings.csv  # Features + embeddings
â”‚   â”œâ”€â”€ duplicates.csv                # Duplicate URL pairs
â”‚   â””â”€â”€ final_features.csv            # All engineered features + labels
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ SEO_Content_Quality_and_Duplicate_Detector.ipynb
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ quality_model.pkl
â”‚   â””â”€â”€ label_encoder.pkl
â”œâ”€â”€ streamlit_app/ (optional)
â”‚   â””â”€â”€ app.py
â””â”€â”€ README.md

âš™ï¸ How to Run (Kaggle Setup)

Upload your dataset â†’ /kaggle/input/dataset-for-assignment/data.csv

Upload this notebook: SEO_Content_Quality_and_Duplicate_Detector.ipynb

In Kaggle Notebook Settings â†’ enable Internet + GPU (T4)

Run all cells top-to-bottom.

Output files will be saved in /kaggle/working/seo_outputs/.

ðŸ“ˆ Outputs
File	Description
extracted_content.csv	Parsed titles, text, and word counts
features_with_embeddings.csv	Engineered features + embeddings
duplicates.csv	URL pairs with cosine similarity > 0.8
final_features.csv	All computed features + quality_label
quality_model.pkl	Trained RandomForest quality predictor
ðŸ§© Key Insights

High Quality â†’ >1500 words, readability between 50â€“70

Low Quality â†’ <500 words or readability <30

Duplicates â†’ cosine similarity â‰¥ 0.8 between embeddings

Thin Content Ratio â†’ pages with <500 words

ðŸŒ Example Test URLs

Use these for demo/testing:

https://www.example.com/
 (short content â†’ Low quality)

https://en.wikipedia.org/wiki/Artificial_intelligence
 (long, detailed â†’ High quality)

https://www.ibm.com/topics/machine-learning
 (medium-length â†’ Medium quality)

ðŸ† Results Summary

Model Accuracy (RandomForest): ~75â€“80% on rule-based labels

Duplicate Detection Threshold: 0.80

Thin Pages Flagged: automatically labeled

âš¡ Future Enhancements

Integrate topic-based clustering for duplicate group detection

Add grammar/keyword density metrics

Deploy Streamlit dashboard for visual analysis
